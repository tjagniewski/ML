{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0HbJ7a_gZQt",
        "outputId": "09317efe-2c12-4189-c5ba-fb2e76ff017f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Train: (50000, 32, 32, 3) (50000,)\n",
            "Test : (10000, 32, 32, 3) (10000,)\n",
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer'] ...\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_y = train_y.squeeze().astype(np.int64)\n",
        "test_y = test_y.squeeze().astype(np.int64)\n",
        "# normalization\n",
        "train_X = train_X.astype(np.float32) / 255.0\n",
        "test_X = test_X.astype(np.float32) / 255.0\n",
        "\n",
        "class_names = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "print(\"Train:\", train_X.shape, train_y.shape)\n",
        "print(\"Test :\", test_X.shape, test_y.shape)\n",
        "print(\"Classes:\", class_names[:5], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8HqWHmDiLY8",
        "outputId": "3f4b8726-66a4-4bdd-c083-39295d959f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Baseline ===\n",
            "Params: 550570\n",
            "Epoch 1/30\n",
            "704/704 - 211s - 300ms/step - accuracy: 0.4314 - loss: 1.5432 - val_accuracy: 0.4986 - val_loss: 1.3286 - learning_rate: 1.0000e-03\n",
            "Epoch 2/30\n",
            "704/704 - 201s - 285ms/step - accuracy: 0.6214 - loss: 1.0601 - val_accuracy: 0.6600 - val_loss: 0.9640 - learning_rate: 1.0000e-03\n",
            "Epoch 3/30\n",
            "704/704 - 202s - 287ms/step - accuracy: 0.7015 - loss: 0.8480 - val_accuracy: 0.7210 - val_loss: 0.8092 - learning_rate: 1.0000e-03\n",
            "Epoch 4/30\n",
            "704/704 - 206s - 292ms/step - accuracy: 0.7517 - loss: 0.7062 - val_accuracy: 0.7496 - val_loss: 0.7490 - learning_rate: 1.0000e-03\n",
            "Epoch 5/30\n",
            "704/704 - 198s - 281ms/step - accuracy: 0.7916 - loss: 0.5930 - val_accuracy: 0.7510 - val_loss: 0.7593 - learning_rate: 1.0000e-03\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 - 207s - 294ms/step - accuracy: 0.8171 - loss: 0.5160 - val_accuracy: 0.7352 - val_loss: 0.8293 - learning_rate: 1.0000e-03\n",
            "Epoch 7/30\n",
            "704/704 - 200s - 284ms/step - accuracy: 0.8684 - loss: 0.3769 - val_accuracy: 0.7654 - val_loss: 0.8041 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 - 201s - 285ms/step - accuracy: 0.9056 - loss: 0.2774 - val_accuracy: 0.7598 - val_loss: 0.9191 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "704/704 - 207s - 294ms/step - accuracy: 0.9279 - loss: 0.2094 - val_accuracy: 0.7832 - val_loss: 0.8526 - learning_rate: 2.5000e-04\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 - 263s - 374ms/step - accuracy: 0.9540 - loss: 0.1459 - val_accuracy: 0.7820 - val_loss: 0.9731 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "704/704 - 263s - 374ms/step - accuracy: 0.9651 - loss: 0.1078 - val_accuracy: 0.7858 - val_loss: 1.0255 - learning_rate: 1.2500e-04\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "704/704 - 211s - 300ms/step - accuracy: 0.9796 - loss: 0.0750 - val_accuracy: 0.7842 - val_loss: 1.1351 - learning_rate: 1.2500e-04\n",
            "Epoch 13/30\n",
            "704/704 - 211s - 300ms/step - accuracy: 0.9856 - loss: 0.0566 - val_accuracy: 0.7926 - val_loss: 1.1820 - learning_rate: 6.2500e-05\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "704/704 - 247s - 351ms/step - accuracy: 0.9917 - loss: 0.0418 - val_accuracy: 0.7936 - val_loss: 1.2586 - learning_rate: 6.2500e-05\n",
            "Epoch 15/30\n",
            "704/704 - 202s - 287ms/step - accuracy: 0.9940 - loss: 0.0336 - val_accuracy: 0.7940 - val_loss: 1.2887 - learning_rate: 3.1250e-05\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "704/704 - 206s - 292ms/step - accuracy: 0.9964 - loss: 0.0271 - val_accuracy: 0.7938 - val_loss: 1.3381 - learning_rate: 3.1250e-05\n",
            "Epoch 17/30\n",
            "704/704 - 200s - 284ms/step - accuracy: 0.9970 - loss: 0.0231 - val_accuracy: 0.7928 - val_loss: 1.3605 - learning_rate: 1.5625e-05\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "704/704 - 215s - 306ms/step - accuracy: 0.9977 - loss: 0.0203 - val_accuracy: 0.7932 - val_loss: 1.3916 - learning_rate: 1.5625e-05\n",
            "Epoch 19/30\n",
            "704/704 - 215s - 305ms/step - accuracy: 0.9980 - loss: 0.0183 - val_accuracy: 0.7896 - val_loss: 1.4073 - learning_rate: 7.8125e-06\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "704/704 - 210s - 299ms/step - accuracy: 0.9984 - loss: 0.0169 - val_accuracy: 0.7896 - val_loss: 1.4261 - learning_rate: 7.8125e-06\n",
            "Baseline | Test accuracy: 0.7725 | Test loss: 1.3964\n",
            "\n",
            "=== + Dropout(0.3) ===\n",
            "Params: 550570\n",
            "Epoch 1/30\n",
            "704/704 - 221s - 314ms/step - accuracy: 0.3553 - loss: 1.7327 - val_accuracy: 0.4886 - val_loss: 1.4081 - learning_rate: 1.0000e-03\n",
            "Epoch 2/30\n",
            "704/704 - 264s - 375ms/step - accuracy: 0.5300 - loss: 1.2992 - val_accuracy: 0.6264 - val_loss: 1.0959 - learning_rate: 1.0000e-03\n",
            "Epoch 3/30\n",
            "704/704 - 228s - 323ms/step - accuracy: 0.6024 - loss: 1.1140 - val_accuracy: 0.6672 - val_loss: 0.9442 - learning_rate: 1.0000e-03\n",
            "Epoch 4/30\n",
            "704/704 - 219s - 311ms/step - accuracy: 0.6445 - loss: 1.0014 - val_accuracy: 0.6954 - val_loss: 0.8534 - learning_rate: 1.0000e-03\n",
            "Epoch 5/30\n",
            "704/704 - 224s - 318ms/step - accuracy: 0.6753 - loss: 0.9116 - val_accuracy: 0.7254 - val_loss: 0.7796 - learning_rate: 1.0000e-03\n",
            "Epoch 6/30\n",
            "704/704 - 235s - 333ms/step - accuracy: 0.6999 - loss: 0.8541 - val_accuracy: 0.7286 - val_loss: 0.7674 - learning_rate: 1.0000e-03\n",
            "Epoch 7/30\n",
            "704/704 - 223s - 317ms/step - accuracy: 0.7185 - loss: 0.8013 - val_accuracy: 0.7462 - val_loss: 0.7201 - learning_rate: 1.0000e-03\n",
            "Epoch 8/30\n",
            "704/704 - 260s - 369ms/step - accuracy: 0.7298 - loss: 0.7638 - val_accuracy: 0.7664 - val_loss: 0.6820 - learning_rate: 1.0000e-03\n",
            "Epoch 9/30\n",
            "704/704 - 227s - 323ms/step - accuracy: 0.7464 - loss: 0.7256 - val_accuracy: 0.7762 - val_loss: 0.6589 - learning_rate: 1.0000e-03\n",
            "Epoch 10/30\n",
            "704/704 - 260s - 369ms/step - accuracy: 0.7535 - loss: 0.7015 - val_accuracy: 0.7630 - val_loss: 0.6684 - learning_rate: 1.0000e-03\n",
            "Epoch 11/30\n",
            "704/704 - 259s - 368ms/step - accuracy: 0.7635 - loss: 0.6772 - val_accuracy: 0.7702 - val_loss: 0.6547 - learning_rate: 1.0000e-03\n",
            "Epoch 12/30\n",
            "704/704 - 217s - 308ms/step - accuracy: 0.7701 - loss: 0.6540 - val_accuracy: 0.7762 - val_loss: 0.6374 - learning_rate: 1.0000e-03\n",
            "Epoch 13/30\n",
            "704/704 - 217s - 308ms/step - accuracy: 0.7744 - loss: 0.6379 - val_accuracy: 0.7858 - val_loss: 0.6284 - learning_rate: 1.0000e-03\n",
            "Epoch 14/30\n",
            "704/704 - 268s - 380ms/step - accuracy: 0.7793 - loss: 0.6249 - val_accuracy: 0.7904 - val_loss: 0.6131 - learning_rate: 1.0000e-03\n",
            "Epoch 15/30\n",
            "704/704 - 256s - 364ms/step - accuracy: 0.7836 - loss: 0.6090 - val_accuracy: 0.7892 - val_loss: 0.6187 - learning_rate: 1.0000e-03\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 - 264s - 375ms/step - accuracy: 0.7897 - loss: 0.5974 - val_accuracy: 0.7828 - val_loss: 0.6334 - learning_rate: 1.0000e-03\n",
            "Epoch 17/30\n",
            "704/704 - 217s - 309ms/step - accuracy: 0.8122 - loss: 0.5307 - val_accuracy: 0.8110 - val_loss: 0.5631 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "704/704 - 219s - 310ms/step - accuracy: 0.8196 - loss: 0.5085 - val_accuracy: 0.8120 - val_loss: 0.5660 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "704/704 - 262s - 372ms/step - accuracy: 0.8246 - loss: 0.4971 - val_accuracy: 0.8138 - val_loss: 0.5577 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "704/704 - 216s - 307ms/step - accuracy: 0.8291 - loss: 0.4795 - val_accuracy: 0.8182 - val_loss: 0.5472 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "704/704 - 260s - 370ms/step - accuracy: 0.8304 - loss: 0.4749 - val_accuracy: 0.8226 - val_loss: 0.5600 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 - 215s - 305ms/step - accuracy: 0.8337 - loss: 0.4668 - val_accuracy: 0.8230 - val_loss: 0.5525 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "704/704 - 259s - 368ms/step - accuracy: 0.8439 - loss: 0.4331 - val_accuracy: 0.8294 - val_loss: 0.5347 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "704/704 - 216s - 307ms/step - accuracy: 0.8521 - loss: 0.4132 - val_accuracy: 0.8262 - val_loss: 0.5477 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "704/704 - 209s - 297ms/step - accuracy: 0.8526 - loss: 0.4082 - val_accuracy: 0.8324 - val_loss: 0.5322 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "704/704 - 210s - 299ms/step - accuracy: 0.8541 - loss: 0.4072 - val_accuracy: 0.8272 - val_loss: 0.5486 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "704/704 - 261s - 371ms/step - accuracy: 0.8562 - loss: 0.3989 - val_accuracy: 0.8294 - val_loss: 0.5284 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "704/704 - 267s - 380ms/step - accuracy: 0.8604 - loss: 0.3888 - val_accuracy: 0.8294 - val_loss: 0.5291 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 - 257s - 366ms/step - accuracy: 0.8590 - loss: 0.3891 - val_accuracy: 0.8310 - val_loss: 0.5431 - learning_rate: 2.5000e-04\n",
            "Epoch 30/30\n",
            "704/704 - 260s - 369ms/step - accuracy: 0.8655 - loss: 0.3696 - val_accuracy: 0.8332 - val_loss: 0.5319 - learning_rate: 1.2500e-04\n",
            "+ Dropout(0.3) | Test accuracy: 0.8234 | Test loss: 0.5777\n",
            "\n",
            "=== + BatchNorm ===\n",
            "Params: 552298\n",
            "Epoch 1/30\n",
            "704/704 - 261s - 371ms/step - accuracy: 0.5963 - loss: 1.1336 - val_accuracy: 0.6298 - val_loss: 1.0603 - learning_rate: 1.0000e-03\n",
            "Epoch 2/30\n",
            "704/704 - 264s - 376ms/step - accuracy: 0.7517 - loss: 0.7105 - val_accuracy: 0.6364 - val_loss: 1.1353 - learning_rate: 1.0000e-03\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 - 328s - 465ms/step - accuracy: 0.8168 - loss: 0.5288 - val_accuracy: 0.5874 - val_loss: 1.5612 - learning_rate: 1.0000e-03\n",
            "Epoch 4/30\n",
            "704/704 - 307s - 436ms/step - accuracy: 0.8922 - loss: 0.3235 - val_accuracy: 0.7192 - val_loss: 0.9376 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "704/704 - 259s - 367ms/step - accuracy: 0.9417 - loss: 0.2043 - val_accuracy: 0.7064 - val_loss: 1.0431 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 - 258s - 367ms/step - accuracy: 0.9718 - loss: 0.1184 - val_accuracy: 0.6652 - val_loss: 1.3785 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "704/704 - 246s - 350ms/step - accuracy: 0.9870 - loss: 0.0614 - val_accuracy: 0.8168 - val_loss: 0.6850 - learning_rate: 2.5000e-04\n",
            "Epoch 8/30\n",
            "704/704 - 240s - 341ms/step - accuracy: 0.9982 - loss: 0.0244 - val_accuracy: 0.8236 - val_loss: 0.7010 - learning_rate: 2.5000e-04\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 - 266s - 378ms/step - accuracy: 0.9998 - loss: 0.0106 - val_accuracy: 0.8250 - val_loss: 0.7244 - learning_rate: 2.5000e-04\n",
            "Epoch 10/30\n",
            "704/704 - 242s - 344ms/step - accuracy: 0.9999 - loss: 0.0058 - val_accuracy: 0.8292 - val_loss: 0.7184 - learning_rate: 1.2500e-04\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "704/704 - 267s - 380ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8300 - val_loss: 0.7392 - learning_rate: 1.2500e-04\n",
            "Epoch 12/30\n",
            "704/704 - 249s - 354ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8310 - val_loss: 0.7464 - learning_rate: 6.2500e-05\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "704/704 - 268s - 380ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8292 - val_loss: 0.7595 - learning_rate: 6.2500e-05\n",
            "Epoch 14/30\n",
            "704/704 - 261s - 370ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8306 - val_loss: 0.7652 - learning_rate: 3.1250e-05\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "704/704 - 262s - 372ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8302 - val_loss: 0.7750 - learning_rate: 3.1250e-05\n",
            "Epoch 16/30\n",
            "704/704 - 252s - 357ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8308 - val_loss: 0.7795 - learning_rate: 1.5625e-05\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "704/704 - 270s - 384ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8304 - val_loss: 0.7869 - learning_rate: 1.5625e-05\n",
            "+ BatchNorm | Test accuracy: 0.8165 | Test loss: 0.7980\n",
            "\n",
            "=== + BatchNorm + Dropout(0.3) ===\n",
            "Params: 552298\n",
            "Epoch 1/30\n",
            "704/704 - 263s - 373ms/step - accuracy: 0.4682 - loss: 1.4812 - val_accuracy: 0.5820 - val_loss: 1.2170 - learning_rate: 1.0000e-03\n",
            "Epoch 2/30\n",
            "704/704 - 249s - 353ms/step - accuracy: 0.6374 - loss: 1.0206 - val_accuracy: 0.6574 - val_loss: 0.9998 - learning_rate: 1.0000e-03\n",
            "Epoch 3/30\n",
            "704/704 - 252s - 357ms/step - accuracy: 0.6971 - loss: 0.8637 - val_accuracy: 0.6726 - val_loss: 0.9765 - learning_rate: 1.0000e-03\n",
            "Epoch 4/30\n",
            "704/704 - 258s - 367ms/step - accuracy: 0.7278 - loss: 0.7750 - val_accuracy: 0.6828 - val_loss: 0.9117 - learning_rate: 1.0000e-03\n",
            "Epoch 5/30\n",
            "704/704 - 256s - 363ms/step - accuracy: 0.7485 - loss: 0.7123 - val_accuracy: 0.7582 - val_loss: 0.6917 - learning_rate: 1.0000e-03\n",
            "Epoch 6/30\n",
            "704/704 - 252s - 357ms/step - accuracy: 0.7698 - loss: 0.6574 - val_accuracy: 0.7572 - val_loss: 0.7083 - learning_rate: 1.0000e-03\n",
            "Epoch 7/30\n",
            "704/704 - 265s - 376ms/step - accuracy: 0.7868 - loss: 0.6115 - val_accuracy: 0.7824 - val_loss: 0.6273 - learning_rate: 1.0000e-03\n",
            "Epoch 8/30\n",
            "704/704 - 271s - 385ms/step - accuracy: 0.7986 - loss: 0.5720 - val_accuracy: 0.7662 - val_loss: 0.6651 - learning_rate: 1.0000e-03\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 - 253s - 360ms/step - accuracy: 0.8122 - loss: 0.5380 - val_accuracy: 0.7740 - val_loss: 0.6515 - learning_rate: 1.0000e-03\n",
            "Epoch 10/30\n",
            "704/704 - 269s - 382ms/step - accuracy: 0.8385 - loss: 0.4645 - val_accuracy: 0.8170 - val_loss: 0.5399 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "704/704 - 292s - 415ms/step - accuracy: 0.8463 - loss: 0.4389 - val_accuracy: 0.8358 - val_loss: 0.4747 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "704/704 - 258s - 366ms/step - accuracy: 0.8520 - loss: 0.4166 - val_accuracy: 0.8086 - val_loss: 0.5747 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 - 257s - 366ms/step - accuracy: 0.8620 - loss: 0.3970 - val_accuracy: 0.8202 - val_loss: 0.5370 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "704/704 - 258s - 367ms/step - accuracy: 0.8736 - loss: 0.3576 - val_accuracy: 0.8530 - val_loss: 0.4470 - learning_rate: 2.5000e-04\n",
            "Epoch 15/30\n",
            "704/704 - 271s - 385ms/step - accuracy: 0.8784 - loss: 0.3450 - val_accuracy: 0.8536 - val_loss: 0.4482 - learning_rate: 2.5000e-04\n",
            "Epoch 16/30\n",
            "704/704 - 262s - 372ms/step - accuracy: 0.8840 - loss: 0.3330 - val_accuracy: 0.8572 - val_loss: 0.4401 - learning_rate: 2.5000e-04\n",
            "Epoch 17/30\n",
            "704/704 - 256s - 364ms/step - accuracy: 0.8854 - loss: 0.3245 - val_accuracy: 0.8614 - val_loss: 0.4314 - learning_rate: 2.5000e-04\n",
            "Epoch 18/30\n",
            "704/704 - 255s - 362ms/step - accuracy: 0.8864 - loss: 0.3177 - val_accuracy: 0.8536 - val_loss: 0.4523 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "704/704 - 256s - 363ms/step - accuracy: 0.8906 - loss: 0.3052 - val_accuracy: 0.8620 - val_loss: 0.4304 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "704/704 - 259s - 368ms/step - accuracy: 0.8938 - loss: 0.2960 - val_accuracy: 0.8588 - val_loss: 0.4366 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 - 247s - 351ms/step - accuracy: 0.8962 - loss: 0.2885 - val_accuracy: 0.8614 - val_loss: 0.4396 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "704/704 - 269s - 382ms/step - accuracy: 0.9022 - loss: 0.2743 - val_accuracy: 0.8630 - val_loss: 0.4226 - learning_rate: 1.2500e-04\n",
            "Epoch 23/30\n",
            "704/704 - 264s - 375ms/step - accuracy: 0.9068 - loss: 0.2627 - val_accuracy: 0.8652 - val_loss: 0.4212 - learning_rate: 1.2500e-04\n",
            "Epoch 24/30\n",
            "704/704 - 267s - 379ms/step - accuracy: 0.9077 - loss: 0.2575 - val_accuracy: 0.8702 - val_loss: 0.4166 - learning_rate: 1.2500e-04\n",
            "Epoch 25/30\n",
            "704/704 - 273s - 387ms/step - accuracy: 0.9108 - loss: 0.2547 - val_accuracy: 0.8656 - val_loss: 0.4264 - learning_rate: 1.2500e-04\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "704/704 - 315s - 448ms/step - accuracy: 0.9124 - loss: 0.2488 - val_accuracy: 0.8668 - val_loss: 0.4268 - learning_rate: 1.2500e-04\n",
            "Epoch 27/30\n",
            "704/704 - 324s - 460ms/step - accuracy: 0.9151 - loss: 0.2382 - val_accuracy: 0.8696 - val_loss: 0.4215 - learning_rate: 6.2500e-05\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "704/704 - 314s - 446ms/step - accuracy: 0.9182 - loss: 0.2345 - val_accuracy: 0.8684 - val_loss: 0.4242 - learning_rate: 6.2500e-05\n",
            "Epoch 29/30\n",
            "704/704 - 261s - 371ms/step - accuracy: 0.9163 - loss: 0.2343 - val_accuracy: 0.8668 - val_loss: 0.4207 - learning_rate: 3.1250e-05\n",
            "+ BatchNorm + Dropout(0.3) | Test accuracy: 0.8563 | Test loss: 0.4375\n",
            "\n",
            "=== PODSUMOWANIE ===\n",
            "Baseline                     params=550570    best_val_acc=0.7940 test_acc=0.7725\n",
            "+ Dropout(0.3)               params=550570    best_val_acc=0.8332 test_acc=0.8234\n",
            "+ BatchNorm                  params=552298    best_val_acc=0.8310 test_acc=0.8165\n",
            "+ BatchNorm + Dropout(0.3)   params=552298    best_val_acc=0.8702 test_acc=0.8563\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "def build_model(use_dropout=False, use_batchnorm=False, dropout_rate=0.3):\n",
        "    def maybe_bn(x):\n",
        "        return layers.BatchNormalization()(x) if use_batchnorm else x\n",
        "\n",
        "    inputs = keras.Input(shape=INPUT_SHAPE)\n",
        "    x = inputs\n",
        "\n",
        "    x = layers.Conv2D(32, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(32, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), padding=\"same\", use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, use_bias=not use_batchnorm)(x)\n",
        "    x = maybe_bn(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def compile_model(model, lr=1e-3):\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "def train_and_eval(model, name, train_X, train_y, test_X, test_y, epochs=20, batch_size=64):\n",
        "    compile_model(model)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Params:\", model.count_params())\n",
        "    history = model.fit(\n",
        "        train_X, train_y,\n",
        "        validation_split=0.1,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
        "    print(f\"{name} | Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")\n",
        "\n",
        "    best_val_acc = max(history.history[\"val_accuracy\"])\n",
        "    best_val_loss = min(history.history[\"val_loss\"])\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"params\": model.count_params(),\n",
        "        \"best_val_acc\": float(best_val_acc),\n",
        "        \"best_val_loss\": float(best_val_loss),\n",
        "        \"test_acc\": float(test_acc),\n",
        "        \"test_loss\": float(test_loss),\n",
        "    }\n",
        "\n",
        "models = [\n",
        "    (\"Baseline\", build_model(use_dropout=False, use_batchnorm=False)),\n",
        "    (\"+ Dropout(0.3)\", build_model(use_dropout=True, use_batchnorm=False, dropout_rate=0.3)),\n",
        "    (\"+ BatchNorm\", build_model(use_dropout=False, use_batchnorm=True)),\n",
        "    (\"+ BatchNorm + Dropout(0.3)\", build_model(use_dropout=True, use_batchnorm=True, dropout_rate=0.3)),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, m in models:\n",
        "    results.append(train_and_eval(m, name, train_X, train_y, test_X, test_y, epochs=30, batch_size=64))\n",
        "\n",
        "print(\"\\n=== PODSUMOWANIE ===\")\n",
        "for r in results:\n",
        "    print(\n",
        "        f\"{r['name']:<28} params={r['params']:<9} \"\n",
        "        f\"best_val_acc={r['best_val_acc']:.4f} test_acc={r['test_acc']:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIzjeOxY71t6",
        "outputId": "f9599019-ad56-49b3-d871-b091ec6c63c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Baseline ===\n",
            "Params: 101402\n",
            "Epoch 1/15\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.4466 - loss: 1.5232 - val_accuracy: 0.5808 - val_loss: 1.1768 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.6200 - loss: 1.0764 - val_accuracy: 0.6502 - val_loss: 0.9826 - learning_rate: 1.0000e-03\n",
            "Epoch 3/15\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.6798 - loss: 0.9118 - val_accuracy: 0.6884 - val_loss: 0.8949 - learning_rate: 1.0000e-03\n",
            "Epoch 4/15\n",
            "1407/1407 - 109s - 77ms/step - accuracy: 0.7163 - loss: 0.8108 - val_accuracy: 0.7148 - val_loss: 0.8121 - learning_rate: 1.0000e-03\n",
            "Epoch 5/15\n",
            "1407/1407 - 109s - 78ms/step - accuracy: 0.7409 - loss: 0.7370 - val_accuracy: 0.7252 - val_loss: 0.7953 - learning_rate: 1.0000e-03\n",
            "Epoch 6/15\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.7658 - loss: 0.6705 - val_accuracy: 0.7260 - val_loss: 0.8130 - learning_rate: 1.0000e-03\n",
            "Epoch 7/15\n",
            "1407/1407 - 143s - 102ms/step - accuracy: 0.7805 - loss: 0.6214 - val_accuracy: 0.7546 - val_loss: 0.7231 - learning_rate: 1.0000e-03\n",
            "Epoch 8/15\n",
            "1407/1407 - 109s - 77ms/step - accuracy: 0.7972 - loss: 0.5741 - val_accuracy: 0.7232 - val_loss: 0.8030 - learning_rate: 1.0000e-03\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.8132 - loss: 0.5288 - val_accuracy: 0.7440 - val_loss: 0.7689 - learning_rate: 1.0000e-03\n",
            "Epoch 10/15\n",
            "1407/1407 - 144s - 103ms/step - accuracy: 0.8604 - loss: 0.4013 - val_accuracy: 0.7518 - val_loss: 0.7872 - learning_rate: 5.0000e-04\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.8732 - loss: 0.3632 - val_accuracy: 0.7426 - val_loss: 0.8407 - learning_rate: 5.0000e-04\n",
            "Epoch 12/15\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.9026 - loss: 0.2848 - val_accuracy: 0.7620 - val_loss: 0.8081 - learning_rate: 2.5000e-04\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1407/1407 - 143s - 102ms/step - accuracy: 0.9123 - loss: 0.2568 - val_accuracy: 0.7562 - val_loss: 0.8786 - learning_rate: 2.5000e-04\n",
            "Epoch 14/15\n",
            "1407/1407 - 109s - 78ms/step - accuracy: 0.9309 - loss: 0.2119 - val_accuracy: 0.7598 - val_loss: 0.9047 - learning_rate: 1.2500e-04\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "1407/1407 - 140s - 99ms/step - accuracy: 0.9369 - loss: 0.1979 - val_accuracy: 0.7586 - val_loss: 0.9333 - learning_rate: 1.2500e-04\n",
            "Baseline | Test accuracy: 0.7449 | Test loss: 0.8943\n",
            "\n",
            "=== + Dropout(0.3) ===\n",
            "Params: 101402\n",
            "Epoch 1/15\n",
            "1407/1407 - 117s - 83ms/step - accuracy: 0.3231 - loss: 1.8105 - val_accuracy: 0.4566 - val_loss: 1.4878 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "1407/1407 - 114s - 81ms/step - accuracy: 0.4625 - loss: 1.4692 - val_accuracy: 0.5398 - val_loss: 1.2790 - learning_rate: 1.0000e-03\n",
            "Epoch 3/15\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.5293 - loss: 1.3064 - val_accuracy: 0.5978 - val_loss: 1.1259 - learning_rate: 1.0000e-03\n",
            "Epoch 4/15\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.5696 - loss: 1.2086 - val_accuracy: 0.6226 - val_loss: 1.0568 - learning_rate: 1.0000e-03\n",
            "Epoch 5/15\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.5915 - loss: 1.1463 - val_accuracy: 0.6560 - val_loss: 0.9655 - learning_rate: 1.0000e-03\n",
            "Epoch 6/15\n",
            "1407/1407 - 113s - 80ms/step - accuracy: 0.6118 - loss: 1.1009 - val_accuracy: 0.6698 - val_loss: 0.9555 - learning_rate: 1.0000e-03\n",
            "Epoch 7/15\n",
            "1407/1407 - 141s - 100ms/step - accuracy: 0.6266 - loss: 1.0560 - val_accuracy: 0.6818 - val_loss: 0.9020 - learning_rate: 1.0000e-03\n",
            "Epoch 8/15\n",
            "1407/1407 - 113s - 80ms/step - accuracy: 0.6392 - loss: 1.0263 - val_accuracy: 0.6800 - val_loss: 0.9054 - learning_rate: 1.0000e-03\n",
            "Epoch 9/15\n",
            "1407/1407 - 114s - 81ms/step - accuracy: 0.6490 - loss: 1.0012 - val_accuracy: 0.7060 - val_loss: 0.8479 - learning_rate: 1.0000e-03\n",
            "Epoch 10/15\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.6580 - loss: 0.9737 - val_accuracy: 0.6958 - val_loss: 0.8444 - learning_rate: 1.0000e-03\n",
            "Epoch 11/15\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.6632 - loss: 0.9555 - val_accuracy: 0.7198 - val_loss: 0.8067 - learning_rate: 1.0000e-03\n",
            "Epoch 12/15\n",
            "1407/1407 - 142s - 101ms/step - accuracy: 0.6724 - loss: 0.9336 - val_accuracy: 0.7002 - val_loss: 0.8630 - learning_rate: 1.0000e-03\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.6767 - loss: 0.9198 - val_accuracy: 0.7168 - val_loss: 0.8181 - learning_rate: 1.0000e-03\n",
            "Epoch 14/15\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.6972 - loss: 0.8532 - val_accuracy: 0.7294 - val_loss: 0.7620 - learning_rate: 5.0000e-04\n",
            "Epoch 15/15\n",
            "1407/1407 - 145s - 103ms/step - accuracy: 0.7082 - loss: 0.8383 - val_accuracy: 0.7360 - val_loss: 0.7401 - learning_rate: 5.0000e-04\n",
            "+ Dropout(0.3) | Test accuracy: 0.7297 | Test loss: 0.7712\n",
            "\n",
            "=== + BatchNorm ===\n",
            "Params: 101402\n",
            "Epoch 1/15\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.4278 - loss: 1.5634 - val_accuracy: 0.5532 - val_loss: 1.2487 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "1407/1407 - 141s - 100ms/step - accuracy: 0.6150 - loss: 1.0885 - val_accuracy: 0.6692 - val_loss: 0.9643 - learning_rate: 1.0000e-03\n",
            "Epoch 3/15\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.6809 - loss: 0.9031 - val_accuracy: 0.6842 - val_loss: 0.9092 - learning_rate: 1.0000e-03\n",
            "Epoch 4/15\n",
            "1407/1407 - 140s - 100ms/step - accuracy: 0.7187 - loss: 0.7958 - val_accuracy: 0.7178 - val_loss: 0.8227 - learning_rate: 1.0000e-03\n",
            "Epoch 5/15\n",
            "1407/1407 - 109s - 77ms/step - accuracy: 0.7474 - loss: 0.7155 - val_accuracy: 0.7002 - val_loss: 0.8714 - learning_rate: 1.0000e-03\n",
            "Epoch 6/15\n",
            "1407/1407 - 109s - 77ms/step - accuracy: 0.7697 - loss: 0.6508 - val_accuracy: 0.7252 - val_loss: 0.7867 - learning_rate: 1.0000e-03\n",
            "Epoch 7/15\n",
            "1407/1407 - 109s - 77ms/step - accuracy: 0.7893 - loss: 0.5921 - val_accuracy: 0.7284 - val_loss: 0.8151 - learning_rate: 1.0000e-03\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1407/1407 - 140s - 100ms/step - accuracy: 0.8100 - loss: 0.5423 - val_accuracy: 0.7246 - val_loss: 0.8131 - learning_rate: 1.0000e-03\n",
            "Epoch 9/15\n",
            "1407/1407 - 145s - 103ms/step - accuracy: 0.8562 - loss: 0.4115 - val_accuracy: 0.7498 - val_loss: 0.7990 - learning_rate: 5.0000e-04\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1407/1407 - 143s - 101ms/step - accuracy: 0.8718 - loss: 0.3650 - val_accuracy: 0.7500 - val_loss: 0.8190 - learning_rate: 5.0000e-04\n",
            "Epoch 11/15\n",
            "1407/1407 - 140s - 99ms/step - accuracy: 0.9055 - loss: 0.2774 - val_accuracy: 0.7580 - val_loss: 0.8820 - learning_rate: 2.5000e-04\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1407/1407 - 141s - 100ms/step - accuracy: 0.9157 - loss: 0.2494 - val_accuracy: 0.7568 - val_loss: 0.9161 - learning_rate: 2.5000e-04\n",
            "Epoch 13/15\n",
            "1407/1407 - 108s - 77ms/step - accuracy: 0.9352 - loss: 0.2029 - val_accuracy: 0.7580 - val_loss: 0.9647 - learning_rate: 1.2500e-04\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "1407/1407 - 110s - 78ms/step - accuracy: 0.9398 - loss: 0.1883 - val_accuracy: 0.7558 - val_loss: 0.9939 - learning_rate: 1.2500e-04\n",
            "Epoch 15/15\n",
            "1407/1407 - 107s - 76ms/step - accuracy: 0.9513 - loss: 0.1632 - val_accuracy: 0.7574 - val_loss: 1.0376 - learning_rate: 6.2500e-05\n",
            "+ BatchNorm | Test accuracy: 0.7493 | Test loss: 0.8977\n",
            "\n",
            "=== + BatchNorm + Dropout(0.3) ===\n",
            "Params: 101402\n",
            "Epoch 1/15\n",
            "1407/1407 - 115s - 81ms/step - accuracy: 0.3433 - loss: 1.7803 - val_accuracy: 0.4772 - val_loss: 1.4384 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "1407/1407 - 112s - 79ms/step - accuracy: 0.4821 - loss: 1.4314 - val_accuracy: 0.5496 - val_loss: 1.2456 - learning_rate: 1.0000e-03\n",
            "Epoch 3/15\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.5376 - loss: 1.2917 - val_accuracy: 0.6056 - val_loss: 1.1039 - learning_rate: 1.0000e-03\n",
            "Epoch 4/15\n",
            "1407/1407 - 112s - 80ms/step - accuracy: 0.5700 - loss: 1.2046 - val_accuracy: 0.6408 - val_loss: 1.0236 - learning_rate: 1.0000e-03\n",
            "Epoch 5/15\n",
            "1407/1407 - 146s - 104ms/step - accuracy: 0.5971 - loss: 1.1349 - val_accuracy: 0.6630 - val_loss: 0.9606 - learning_rate: 1.0000e-03\n",
            "Epoch 6/15\n",
            "1407/1407 - 140s - 99ms/step - accuracy: 0.6188 - loss: 1.0742 - val_accuracy: 0.6916 - val_loss: 0.8961 - learning_rate: 1.0000e-03\n",
            "Epoch 7/15\n",
            "1407/1407 - 144s - 103ms/step - accuracy: 0.6364 - loss: 1.0297 - val_accuracy: 0.6868 - val_loss: 0.8864 - learning_rate: 1.0000e-03\n",
            "Epoch 8/15\n",
            "1407/1407 - 113s - 80ms/step - accuracy: 0.6482 - loss: 0.9990 - val_accuracy: 0.7042 - val_loss: 0.8600 - learning_rate: 1.0000e-03\n",
            "Epoch 9/15\n",
            "1407/1407 - 143s - 101ms/step - accuracy: 0.6586 - loss: 0.9670 - val_accuracy: 0.7288 - val_loss: 0.7967 - learning_rate: 1.0000e-03\n",
            "Epoch 10/15\n",
            "1407/1407 - 114s - 81ms/step - accuracy: 0.6688 - loss: 0.9406 - val_accuracy: 0.7246 - val_loss: 0.8100 - learning_rate: 1.0000e-03\n",
            "Epoch 11/15\n",
            "1407/1407 - 113s - 80ms/step - accuracy: 0.6785 - loss: 0.9176 - val_accuracy: 0.7246 - val_loss: 0.7878 - learning_rate: 1.0000e-03\n",
            "Epoch 12/15\n",
            "1407/1407 - 113s - 80ms/step - accuracy: 0.6818 - loss: 0.9025 - val_accuracy: 0.7314 - val_loss: 0.7751 - learning_rate: 1.0000e-03\n",
            "Epoch 13/15\n",
            "1407/1407 - 112s - 79ms/step - accuracy: 0.6903 - loss: 0.8810 - val_accuracy: 0.7270 - val_loss: 0.7787 - learning_rate: 1.0000e-03\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1407/1407 - 111s - 79ms/step - accuracy: 0.6951 - loss: 0.8693 - val_accuracy: 0.7302 - val_loss: 0.7779 - learning_rate: 1.0000e-03\n",
            "Epoch 15/15\n",
            "1407/1407 - 115s - 81ms/step - accuracy: 0.7173 - loss: 0.8048 - val_accuracy: 0.7634 - val_loss: 0.6874 - learning_rate: 5.0000e-04\n",
            "+ BatchNorm + Dropout(0.3) | Test accuracy: 0.7476 | Test loss: 0.7272\n",
            "\n",
            "=== Summary ===\n",
            "Baseline                     params=101402    best_val_acc=0.7620 test_acc=0.7449\n",
            "+ Dropout(0.3)               params=101402    best_val_acc=0.7360 test_acc=0.7297\n",
            "+ BatchNorm                  params=101402    best_val_acc=0.7580 test_acc=0.7493\n",
            "+ BatchNorm + Dropout(0.3)   params=101402    best_val_acc=0.7634 test_acc=0.7476\n"
          ]
        }
      ],
      "source": [
        "def build_model(use_dropout=False, use_batchnorm=False, dropout_rate=0.3):\n",
        "    inputs = keras.Input(shape=(32,32,3))\n",
        "    x = inputs\n",
        "\n",
        "    \n",
        "    x = layers.Conv2D(16,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(16,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    if use_dropout: x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    \n",
        "    x = layers.Conv2D(32,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(32,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    if use_dropout: x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    \n",
        "    x = layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    if use_dropout: x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "def compile_model(model, lr=1e-3):\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "def train_and_eval(model, name, train_X, train_y, test_X, test_y, epochs=20, batch_size=64):\n",
        "    compile_model(model)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Params:\", model.count_params())\n",
        "    history = model.fit(\n",
        "        train_X, train_y,\n",
        "        validation_split=0.1,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
        "    print(f\"{name} | Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")\n",
        "\n",
        "    # The best version\n",
        "    best_val_acc = max(history.history[\"val_accuracy\"])\n",
        "    best_val_loss = min(history.history[\"val_loss\"])\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"params\": model.count_params(),\n",
        "        \"best_val_acc\": float(best_val_acc),\n",
        "        \"best_val_loss\": float(best_val_loss),\n",
        "        \"test_acc\": float(test_acc),\n",
        "        \"test_loss\": float(test_loss),\n",
        "    }\n",
        "\n",
        "# different models\n",
        "models = [\n",
        "    (\"Baseline\", build_model(use_dropout=False, use_batchnorm=False)),\n",
        "    (\"+ Dropout(0.3)\", build_model(use_dropout=True, use_batchnorm=False, dropout_rate=0.3)),\n",
        "    (\"+ BatchNorm\", build_model(use_dropout=False, use_batchnorm=True)),\n",
        "    (\"+ BatchNorm + Dropout(0.3)\", build_model(use_dropout=True, use_batchnorm=True, dropout_rate=0.3)),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, m in models:\n",
        "    results.append(train_and_eval(m, name, train_X, train_y, test_X, test_y, epochs=15, batch_size=32))\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "for r in results:\n",
        "    print(\n",
        "        f\"{r['name']:<28} params={r['params']:<9} \"\n",
        "        f\"best_val_acc={r['best_val_acc']:.4f} test_acc={r['test_acc']:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKF3uw728XyZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
